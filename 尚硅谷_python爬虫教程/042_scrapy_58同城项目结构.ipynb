{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scrapy 58同城项目结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. scrapy 项目的结构  \n",
    "```plaintext\n",
    "项目名字  \n",
    "    项目名字\n",
    "        spider文件夹    （存储的是爬虫文件）\n",
    "            __init__.py\n",
    "            自定义的爬虫文件.py     （核心功能文件）**********\n",
    "        __init__.py\n",
    "        items.py        (定义数据结构的地方 爬取的数据都包含哪些)\n",
    "        middlewares.py  (中间件文件         代理)    \n",
    "        pipelines.py    (管道文件   用来处理下载的数据)\n",
    "        settings.py     (配置文件   robots协议 ua定义等)\n",
    "```\n",
    "## 2. response的属性和方法\n",
    "```plaintext\n",
    "response.text 获取的是响应的字符串\n",
    "response.body 获取的是响应的二进制数据\n",
    "response.xpath('') 可以直接使用xpath方法来解析response中的内容\n",
    "response.extract() 提取selector对象的data属性值  -> 下一节介绍\n",
    "response.extract_first() 提取selector列表的第一个的值  -> 下一节介绍\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# 创建项目\n",
    "scrapy startproject scrapy_58tc_042\n",
    "\n",
    "cd scrapy_58tc_042/scrapy_58tc_042/spiders\n",
    "\n",
    "# 创建爬虫文件\n",
    "scrapy genspider tc https://sh.58.com/sou/?key=%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91&button=%E6%90%9C%C2%A0%E7%B4%A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapy_58tc_042/scrapy_58tc_042/spiders/tc.py\n",
    "\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class TcSpider(scrapy.Spider):\n",
    "    name = \"tc\"\n",
    "    allowed_domains = [\"sh.58.com\"]\n",
    "    start_urls = [\"https://sh.58.com/sou/?key=%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91\"]\n",
    "\n",
    "    def parse(self, response):\n",
    "        print(\"山东菏泽曹县\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# 运行爬虫\n",
    "scrapy crawl tc\n",
    "# 没有返回山东菏泽曹县\n",
    "# 将settings中的ROBOTSTXT_OBEY = True注释掉\n",
    "# 之后运行成功"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探索tc.py\n",
    "# 注意每次运行都需要在终端命令行中输入scrapy crawl tc\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class TcSpider(scrapy.Spider):\n",
    "    name = \"tc\"\n",
    "    allowed_domains = [\"sh.58.com\"]\n",
    "    start_urls = [\"https://sh.58.com/sou/?key=%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91\"]\n",
    "\n",
    "    def parse(self, response):\n",
    "        # 字符串\n",
    "        content = response.text\n",
    "        print(\"=========================\")\n",
    "        print(content)\n",
    "\n",
    "        # 二进制数据\n",
    "        content = response.body\n",
    "        print(\"=========================\")\n",
    "        print(content)\n",
    "\n",
    "        span = response.xpath('//div[@id=\"filter\"]/div[@class=\"tabs\"]/a/span')[0]\n",
    "        print(\"=========================\")\n",
    "        print(span) # <Selector xpath='//div[@id=\"filter\"]/div[@class=\"tabs\"]/a/span' data='<span>全部</span>'>\n",
    "        print(\"=========================\")\n",
    "        print(span.extract()) # <span>全部</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrapy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
