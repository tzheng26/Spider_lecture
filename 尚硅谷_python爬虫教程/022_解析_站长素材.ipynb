{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解析 站长素材"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# （1）请求对象的定制\n",
    "# （2）获取网页的源码\n",
    "# （3）下载\n",
    "\n",
    "# 需求：下载前十页的图片 \n",
    "# https://sc.chinaz.com/tupian/qinglvtupian.html\n",
    "# https://sc.chinaz.com/tupian/qinglvtupian_2.html\n",
    "# https://sc.chinaz.com/tupian/qinglvtupian_page.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from lxml import etree\n",
    "import os\n",
    "\n",
    "def create_request(page):\n",
    "    if page == 1:\n",
    "        url = 'https://sc.chinaz.com/tupian/qinglvtupian.html'\n",
    "    else:\n",
    "        url = 'https://sc.chinaz.com/tupian/qinglvtupian_' + str(page) + '.html'\n",
    "    \n",
    "    headers = {\n",
    "        'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',\n",
    "        'cookie': 'cz_statistics_visitor=5f44c562-7c22-a6a8-571b-19048cb8f903; Hm_lvt_398913ed58c9e7dfe9695953fb7b6799=1733377217; HMACCOUNT=52AB44D21035A831; _clck=avqsie%7C2%7Cfrg%7C0%7C1800; _clsk=ra7x14%7C1733377218810%7C1%7C1%7Cu.clarity.ms%2Fcollect; Hm_lpvt_398913ed58c9e7dfe9695953fb7b6799=1733381448'\n",
    "    }\n",
    "    request = urllib.request.Request(url=url, headers=headers)\n",
    "    return request\n",
    "\n",
    "def get_content(request):\n",
    "    response = urllib.request.urlopen(request)\n",
    "    content = response.read().decode('utf-8')\n",
    "    # print(content)\n",
    "    return content\n",
    "\n",
    "def down_load(content, page):\n",
    "    # 下载图片\n",
    "    # urllib.request.urlretrieve('图片地址', '文件名')\n",
    "    \n",
    "    tree = etree.HTML(content)\n",
    "    \n",
    "    # 可以在浏览器通过xpath插件获取xpath路径\n",
    "    # 但有时候爬取的源码和浏览器看到的不一样，需要根据content源码来定位\n",
    "    # name_list = tree.xpath('//div[@class=\"container\"]//a/img/@alt')\n",
    "    name_list = tree.xpath('//div[@class=\"item\"]/img/@alt')\n",
    "    src_list = tree.xpath('//div[@class=\"item\"]/img/@data-original')\n",
    "    # 有的时候 len(src_list)会为0\n",
    "    # 这是因为一般涉及图片的网站都会进行懒加载，只有真正浏览到才会变为src，之前是src2\n",
    "    # src_list = tree.xpath('//div[@class=\"item\"]/img/@src2')\n",
    "    print(len(name_list), len(src_list))\n",
    "\n",
    "\n",
    "    os.makedirs('./loveImg', exist_ok=True)\n",
    "    for i in range(len(name_list)):\n",
    "        name = name_list[i]\n",
    "        src = src_list[i]\n",
    "        url = 'https:' + src\n",
    "        urllib.request.urlretrieve(url=url, filename='./loveImg/' + name + '.jpg')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_page = int(input('请输入起始页码：'))\n",
    "    end_page = int(input('请输入结束页码：'))\n",
    "\n",
    "    for page in range(start_page, end_page + 1):\n",
    "        # （1）请求对象的定制\n",
    "        request = create_request(page)\n",
    "        # （2）获取网页的源码\n",
    "        content = get_content(request)\n",
    "        # （3）下载\n",
    "        down_load(content, page)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
