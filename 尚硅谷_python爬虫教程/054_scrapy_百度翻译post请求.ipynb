{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scrapy_百度翻译post请求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "scrapy startproject scrapy_post_054\n",
    "\n",
    "cd scrapy_post_054/scrapy_post_054/spiders/\n",
    "\n",
    "scrapy genspider testpost https://fanyi.baidu.com/sug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapy_post_054/scrapy_post_054/spiders/testpost.py\n",
    "\n",
    "import scrapy\n",
    "import json\n",
    "\n",
    "class TestpostSpider(scrapy.Spider):\n",
    "    name = \"testpost\"\n",
    "    allowed_domains = [\"fanyi.baidu.com\"]\n",
    "    # post请求如果没有参数，那么这个请求将没有任何意义\n",
    "    # 所以start_urls也没有用了\n",
    "    # parse方法也没有用了\n",
    "    # start_urls = [\"https://fanyi.baidu.com/sug\"]\n",
    "\n",
    "    # def parse(self, response):\n",
    "    #     pass\n",
    "\n",
    "\n",
    "    def start_requests(self):\n",
    "        url = \"https://fanyi.baidu.com/sug\"\n",
    "\n",
    "        data = {\n",
    "            \"kw\": \"final\"\n",
    "        }\n",
    "\n",
    "        yield scrapy.FormRequest(url=url, formdata=data, callback=self.parse_second)\n",
    "\n",
    "\n",
    "    def parse_second(self, response):\n",
    "\n",
    "        content = response.text\n",
    "        obj = json.loads(content, encoding=\"utf-8\")\n",
    "\n",
    "        print(obj)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
