{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解析 bs4的基本使用\n",
    "\n",
    "## 基本简介\n",
    "\n",
    "1. BeautifulSoup简称：\n",
    "\n",
    "    bs4\n",
    "\n",
    "2. 什么是BeautifulSoup？\n",
    "\n",
    "    BeautifulSoup和lxml一样，是一个html的解析器，注意功能也是解析和提取数据\n",
    "\n",
    "3. 优缺点？\n",
    "\n",
    "    缺点：效率没有lxml高\n",
    "    \n",
    "    优点：接口设计人性化，使用方便\n",
    "\n",
    "## 安装及创建\n",
    "\n",
    "1. 安装\n",
    "\n",
    "    ```shell\n",
    "    pip install bs4\n",
    "    ```\n",
    "\n",
    "2. 导入\n",
    "\n",
    "    ```python\n",
    "    from bs4 import BeautifulSoup\n",
    "    ```\n",
    "\n",
    "3. 创建对象\n",
    "\n",
    "    1. 从服务器响应的文件生成对象\n",
    "\n",
    "        ```python\n",
    "        soup = BeautifulSoup(response.read().decode(), 'lxml')\n",
    "        ```\n",
    "\n",
    "    2. 从本地文件生成对象\n",
    "\n",
    "        ```python\n",
    "        with open('index.html', 'r') as f:\n",
    "            soup = BeautifulSoup(f, 'lxml')\n",
    "        \n",
    "        soup = BeautifulSoup(open('index.html', 'r'), 'lxml')\n",
    "        ```\n",
    "\n",
    "## 节点定位\n",
    "\n",
    " 1. 根据标签名查找节点\n",
    "    \n",
    "    soup.a  【注】只能找到第一个a\n",
    "\n",
    "        soup.a.name\n",
    "\n",
    "        soup.a.attrs\n",
    "        \n",
    " 2. 函数\n",
    "    1. find\n",
    "    2. find_all\n",
    "    3. select\n",
    "\n",
    "## 节点信息\n",
    "\n",
    "1. 获取节点内容：适用于标签中嵌套标签的结构\n",
    "   \n",
    "   obj.string\n",
    "   \n",
    "   obj.get_text() 【推荐】\n",
    "\n",
    "2. 节点的属性\n",
    "\n",
    "    tag.name 获取标签名\n",
    "\n",
    "        eg:tag = find('li')\n",
    "            \n",
    "            print(tag.name)\n",
    "\n",
    "    tag.attrs 将属性值作为一个字典返回\n",
    "\n",
    "3. 获取节点的属性值\n",
    "   \n",
    "    obj.attrs.get('title') 【常用】\n",
    "\n",
    "    obj.get('title')\n",
    "    \n",
    "    obj['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 通过解析本地文件 讲解bs4的基本语法\n",
    "# 默认打开的文件的编码格式是gbk，所以在打开文件的时候需要制定编码\n",
    "soup = BeautifulSoup(open('075_解析_bs4的基本使用.html', encoding=\"utf-8\"), 'lxml')\n",
    "\n",
    "# print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"a1\" href=\"\" id=\"\">尚硅谷</a>\n",
      "{'href': '', 'id': '', 'class': ['a1']}\n"
     ]
    }
   ],
   "source": [
    "# 根据标签名查找节点\n",
    "# 找到的是第一个符合条件的数据\n",
    "print(soup.a)\n",
    "\n",
    "# 获取标签的属性和属性值\n",
    "print(soup.a.attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "source": [
    "### bs4的一些函数\n",
    " (1) find\n",
    "\n",
    " (2) find_all\n",
    "\n",
    " (3) select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"a1\" href=\"\" id=\"\">尚硅谷</a>\n",
      "<a href=\"\" title=\"a2\">百度</a>\n",
      "<a class=\"a1\" href=\"\" id=\"\">尚硅谷</a>\n"
     ]
    }
   ],
   "source": [
    "# (1) find\n",
    "# 返回的是第一个符合条件的数据\n",
    "print(soup.find('a'))\n",
    "\n",
    "\n",
    "# 根据标签属性的值找到对应的标签对象  E.g.,:\n",
    "\n",
    "# 根据title的值来找到对应的标签对象\n",
    "print(soup.find('a', title=\"a2\"))\n",
    "\n",
    "# 根据class的值来找到对应的标签对象     注意： class -> class_\n",
    "print(soup.find('a', class_=\"a1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"a1\" href=\"\" id=\"\">尚硅谷</a>, <a href=\"\" title=\"a2\">百度</a>]\n",
      "[<a class=\"a1\" href=\"\" id=\"\">尚硅谷</a>, <span>哈哈哈</span>, <a href=\"\" title=\"a2\">百度</a>, <span>\n",
      "            哈哈哈\n",
      "        </span>]\n",
      "[<li id=\"l1\">张三</li>, <li id=\"l2\">李四</li>]\n"
     ]
    }
   ],
   "source": [
    "# (2) find_all  返回的是一个列表    \n",
    "# 返回所有的a标签\n",
    "print(soup.find_all('a'))\n",
    "\n",
    "# 如果想获取的是多个标签的数据，那么需要在find_all的参数中添加的是列表\n",
    "print(soup.find_all(['a', 'span']))\n",
    "\n",
    "# limit的作用是查找前几个数据\n",
    "print(soup.find_all('li', limit=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"a1\" href=\"\" id=\"\">尚硅谷</a>, <a href=\"\" title=\"a2\">百度</a>]\n",
      "[<a class=\"a1\" href=\"\" id=\"\">尚硅谷</a>]\n",
      "[<li id=\"l1\">张三</li>]\n",
      "[<li id=\"l1\">张三</li>, <li id=\"l2\">李四</li>]\n",
      "[<li id=\"l2\">李四</li>]\n",
      "[<li id=\"l1\">张三</li>, <li id=\"l2\">李四</li>, <li>王五</li>]\n",
      "[<li id=\"l1\">张三</li>, <li id=\"l2\">李四</li>, <li>王五</li>]\n",
      "[<li id=\"l1\">张三</li>, <li id=\"l2\">李四</li>, <li>王五</li>]\n",
      "[<li id=\"l1\">张三</li>, <li id=\"l2\">李四</li>, <li>王五</li>, <a class=\"a1\" href=\"\" id=\"\">尚硅谷</a>, <a href=\"\" title=\"a2\">百度</a>]\n"
     ]
    }
   ],
   "source": [
    "# (3) select（推荐）\n",
    "# select()方法返回的是一个列表  并且会返回多个数据\n",
    "print(soup.select('a'))\n",
    "\n",
    "# 可以通过.代表class    我们把这种操作叫做类选择器（前端的一种说法）\n",
    "print(soup.select('.a1'))\n",
    "\n",
    "# 可以通过#代表id    \n",
    "print(soup.select('#l1'))\n",
    "\n",
    "# 属性选择器---通过属性来寻找对应的标签\n",
    "# 查找到li标签中有id的标签\n",
    "print(soup.select('li[id]'))\n",
    "\n",
    "# 查找li标签中id为l2的标签\n",
    "print(soup.select('li[id=\"l2\"]'))\n",
    "\n",
    "# 层级选择器\n",
    "#  后代选择器\n",
    "#   找到的是div下面的li\n",
    "print(soup.select('div li'))\n",
    "\n",
    "#  子代选择器\n",
    "#   某标签的第一级子标签\n",
    "#   注意：很多的计算机编程语言中，如果不加空格不会输出内容，但是在bs4中不会报错，也会输出内容\n",
    "print(soup.select('div > ul > li'))\n",
    "print(soup.select('div>ul>li'))\n",
    "\n",
    "# 找到a标签和li标签的所有的对象\n",
    "print(soup.select('a, li'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "\n",
      "            哈哈哈\n",
      "        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 节点信息\n",
    "\n",
    "#   获取节点内容\n",
    "obj = soup.select('#d1')[0]\n",
    "\n",
    "# 如果标签对象中只有内容，那么string和get_text()是一样的\n",
    "# 如果标签对象中除了内容还有标签，那么string就获取不到数据，而get_text()可以获取到数据\n",
    "# 一般推荐使用get_text()\n",
    "print(obj.string)\n",
    "print(obj.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p\n",
      "{'id': 'p1', 'class': ['p1']}\n"
     ]
    }
   ],
   "source": [
    "#   节点的属性\n",
    "obj = soup.select('#p1')[0]\n",
    "\n",
    "# name是标签的名字\n",
    "print(obj.name)\n",
    "# 将属性值作为一个字典返回\n",
    "print(obj.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p1']\n",
      "['p1']\n",
      "['p1']\n"
     ]
    }
   ],
   "source": [
    "# 获取节点的属性\n",
    "obj = soup.select('#p1')[0]\n",
    "\n",
    "print(obj.attrs.get('class'))\n",
    "print(obj.get('class'))\n",
    "print(obj['class'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
